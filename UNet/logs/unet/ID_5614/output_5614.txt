Beginning to load data...
 -- Train dataset size: 4134 / 4593 ~ 0.9
 -- Test dataset size: 459 / 4593 ~ 0.1
 -- Created DataLoaders with batch size: 8

Starting UNet Training...
  Epoch [1/100], Batch [47/517], Loss: 0.7286
  Epoch [1/100], Batch [94/517], Loss: 0.6594
  Epoch [1/100], Batch [141/517], Loss: 0.5185
  Epoch [1/100], Batch [188/517], Loss: 0.5227
  Epoch [1/100], Batch [235/517], Loss: 0.5212
  Epoch [1/100], Batch [282/517], Loss: 0.4468
  Epoch [1/100], Batch [329/517], Loss: 0.4362
  Epoch [1/100], Batch [376/517], Loss: 0.4478
  Epoch [1/100], Batch [423/517], Loss: 0.4511
  Epoch [1/100], Batch [470/517], Loss: 0.4263
  Epoch [1/100], Batch [517/517], Loss: 0.3952
--- Epoch [1/100] complete. Average Training Loss: 0.5182 ---
--- Time taken for epoch: 314.52 seconds ---
  Epoch [2/100], Batch [47/517], Loss: 0.4239
  Epoch [2/100], Batch [94/517], Loss: 0.4399
  Epoch [2/100], Batch [141/517], Loss: 0.4298
  Epoch [2/100], Batch [188/517], Loss: 0.4154
  Epoch [2/100], Batch [235/517], Loss: 0.4616
  Epoch [2/100], Batch [282/517], Loss: 0.4180
  Epoch [2/100], Batch [329/517], Loss: 0.4312
  Epoch [2/100], Batch [376/517], Loss: 0.3811
  Epoch [2/100], Batch [423/517], Loss: 0.3167
  Epoch [2/100], Batch [470/517], Loss: 0.3852
  Epoch [2/100], Batch [517/517], Loss: 0.4229
--- Epoch [2/100] complete. Average Training Loss: 0.4085 ---
--- Time taken for epoch: 314.26 seconds ---
  Epoch [3/100], Batch [47/517], Loss: 0.3874
  Epoch [3/100], Batch [94/517], Loss: 0.4357
  Epoch [3/100], Batch [141/517], Loss: 0.4097
  Epoch [3/100], Batch [188/517], Loss: 0.4291
  Epoch [3/100], Batch [235/517], Loss: 0.3989
  Epoch [3/100], Batch [282/517], Loss: 0.4204
  Epoch [3/100], Batch [329/517], Loss: 0.2912
  Epoch [3/100], Batch [376/517], Loss: 0.3021
  Epoch [3/100], Batch [423/517], Loss: 0.4166
  Epoch [3/100], Batch [470/517], Loss: 0.3765
  Epoch [3/100], Batch [517/517], Loss: 0.2799
--- Epoch [3/100] complete. Average Training Loss: 0.3888 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [4/100], Batch [47/517], Loss: 0.4832
  Epoch [4/100], Batch [94/517], Loss: 0.4230
  Epoch [4/100], Batch [141/517], Loss: 0.3605
  Epoch [4/100], Batch [188/517], Loss: 0.4401
  Epoch [4/100], Batch [235/517], Loss: 0.3929
  Epoch [4/100], Batch [282/517], Loss: 0.4302
  Epoch [4/100], Batch [329/517], Loss: 0.4166
  Epoch [4/100], Batch [376/517], Loss: 0.4341
  Epoch [4/100], Batch [423/517], Loss: 0.4497
  Epoch [4/100], Batch [470/517], Loss: 0.4257
  Epoch [4/100], Batch [517/517], Loss: 0.4250
--- Epoch [4/100] complete. Average Training Loss: 0.3780 ---
--- Time taken for epoch: 314.12 seconds ---
  Epoch [5/100], Batch [47/517], Loss: 0.3437
  Epoch [5/100], Batch [94/517], Loss: 0.4228
  Epoch [5/100], Batch [141/517], Loss: 0.3470
  Epoch [5/100], Batch [188/517], Loss: 0.4118
  Epoch [5/100], Batch [235/517], Loss: 0.3894
  Epoch [5/100], Batch [282/517], Loss: 0.3472
  Epoch [5/100], Batch [329/517], Loss: 0.3820
  Epoch [5/100], Batch [376/517], Loss: 0.4494
  Epoch [5/100], Batch [423/517], Loss: 0.3362
  Epoch [5/100], Batch [470/517], Loss: 0.4243
  Epoch [5/100], Batch [517/517], Loss: 0.3365
--- Epoch [5/100] complete. Average Training Loss: 0.3669 ---
--- Time taken for epoch: 314.17 seconds ---
  Epoch [6/100], Batch [47/517], Loss: 0.3576
  Epoch [6/100], Batch [94/517], Loss: 0.3408
  Epoch [6/100], Batch [141/517], Loss: 0.4709
  Epoch [6/100], Batch [188/517], Loss: 0.4130
  Epoch [6/100], Batch [235/517], Loss: 0.4222
  Epoch [6/100], Batch [282/517], Loss: 0.4296
  Epoch [6/100], Batch [329/517], Loss: 0.2551
  Epoch [6/100], Batch [376/517], Loss: 0.4522
  Epoch [6/100], Batch [423/517], Loss: 0.3845
  Epoch [6/100], Batch [470/517], Loss: 0.4414
  Epoch [6/100], Batch [517/517], Loss: 0.2785
--- Epoch [6/100] complete. Average Training Loss: 0.3667 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [7/100], Batch [47/517], Loss: 0.4259
  Epoch [7/100], Batch [94/517], Loss: 0.3848
  Epoch [7/100], Batch [141/517], Loss: 0.4211
  Epoch [7/100], Batch [188/517], Loss: 0.3124
  Epoch [7/100], Batch [235/517], Loss: 0.3926
  Epoch [7/100], Batch [282/517], Loss: 0.2978
  Epoch [7/100], Batch [329/517], Loss: 0.2933
  Epoch [7/100], Batch [376/517], Loss: 0.4750
  Epoch [7/100], Batch [423/517], Loss: 0.4370
  Epoch [7/100], Batch [470/517], Loss: 0.3275
  Epoch [7/100], Batch [517/517], Loss: 0.4190
--- Epoch [7/100] complete. Average Training Loss: 0.3599 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [8/100], Batch [47/517], Loss: 0.4264
  Epoch [8/100], Batch [94/517], Loss: 0.2501
  Epoch [8/100], Batch [141/517], Loss: 0.2638
  Epoch [8/100], Batch [188/517], Loss: 0.2473
  Epoch [8/100], Batch [235/517], Loss: 0.4240
  Epoch [8/100], Batch [282/517], Loss: 0.3960
  Epoch [8/100], Batch [329/517], Loss: 0.4545
  Epoch [8/100], Batch [376/517], Loss: 0.3512
  Epoch [8/100], Batch [423/517], Loss: 0.2929
  Epoch [8/100], Batch [470/517], Loss: 0.3978
  Epoch [8/100], Batch [517/517], Loss: 0.2348
--- Epoch [8/100] complete. Average Training Loss: 0.3591 ---
--- Time taken for epoch: 314.19 seconds ---
  Epoch [9/100], Batch [47/517], Loss: 0.2648
  Epoch [9/100], Batch [94/517], Loss: 0.4274
  Epoch [9/100], Batch [141/517], Loss: 0.2516
  Epoch [9/100], Batch [188/517], Loss: 0.3605
  Epoch [9/100], Batch [235/517], Loss: 0.3083
  Epoch [9/100], Batch [282/517], Loss: 0.3916
  Epoch [9/100], Batch [329/517], Loss: 0.4341
  Epoch [9/100], Batch [376/517], Loss: 0.3507
  Epoch [9/100], Batch [423/517], Loss: 0.3195
  Epoch [9/100], Batch [470/517], Loss: 0.2369
  Epoch [9/100], Batch [517/517], Loss: 0.3720
--- Epoch [9/100] complete. Average Training Loss: 0.3535 ---
--- Time taken for epoch: 314.19 seconds ---
  Epoch [10/100], Batch [47/517], Loss: 0.3475
  Epoch [10/100], Batch [94/517], Loss: 0.1933
  Epoch [10/100], Batch [141/517], Loss: 0.2624
  Epoch [10/100], Batch [188/517], Loss: 0.3582
  Epoch [10/100], Batch [235/517], Loss: 0.4225
  Epoch [10/100], Batch [282/517], Loss: 0.3613
  Epoch [10/100], Batch [329/517], Loss: 0.3401
  Epoch [10/100], Batch [376/517], Loss: 0.4034
  Epoch [10/100], Batch [423/517], Loss: 0.3075
  Epoch [10/100], Batch [470/517], Loss: 0.3487
  Epoch [10/100], Batch [517/517], Loss: 0.4567
--- Epoch [10/100] complete. Average Training Loss: 0.3468 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [11/100], Batch [47/517], Loss: 0.1967
  Epoch [11/100], Batch [94/517], Loss: 0.4452
  Epoch [11/100], Batch [141/517], Loss: 0.3491
  Epoch [11/100], Batch [188/517], Loss: 0.3362
  Epoch [11/100], Batch [235/517], Loss: 0.2654
  Epoch [11/100], Batch [282/517], Loss: 0.3533
  Epoch [11/100], Batch [329/517], Loss: 0.3642
  Epoch [11/100], Batch [376/517], Loss: 0.4250
  Epoch [11/100], Batch [423/517], Loss: 0.4018
  Epoch [11/100], Batch [470/517], Loss: 0.4177
  Epoch [11/100], Batch [517/517], Loss: 0.4191
--- Epoch [11/100] complete. Average Training Loss: 0.3402 ---
--- Time taken for epoch: 314.33 seconds ---
  Epoch [12/100], Batch [47/517], Loss: 0.2358
  Epoch [12/100], Batch [94/517], Loss: 0.4065
  Epoch [12/100], Batch [141/517], Loss: 0.2443
  Epoch [12/100], Batch [188/517], Loss: 0.3959
  Epoch [12/100], Batch [235/517], Loss: 0.4199
  Epoch [12/100], Batch [282/517], Loss: 0.3693
  Epoch [12/100], Batch [329/517], Loss: 0.3986
  Epoch [12/100], Batch [376/517], Loss: 0.3931
  Epoch [12/100], Batch [423/517], Loss: 0.3727
  Epoch [12/100], Batch [470/517], Loss: 0.3742
  Epoch [12/100], Batch [517/517], Loss: 0.2986
--- Epoch [12/100] complete. Average Training Loss: 0.3405 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [13/100], Batch [47/517], Loss: 0.4200
  Epoch [13/100], Batch [94/517], Loss: 0.4496
  Epoch [13/100], Batch [141/517], Loss: 0.4016
  Epoch [13/100], Batch [188/517], Loss: 0.2446
  Epoch [13/100], Batch [235/517], Loss: 0.4387
  Epoch [13/100], Batch [282/517], Loss: 0.4216
  Epoch [13/100], Batch [329/517], Loss: 0.3128
  Epoch [13/100], Batch [376/517], Loss: 0.3367
  Epoch [13/100], Batch [423/517], Loss: 0.3924
  Epoch [13/100], Batch [470/517], Loss: 0.3334
  Epoch [13/100], Batch [517/517], Loss: 0.2935
--- Epoch [13/100] complete. Average Training Loss: 0.3316 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [14/100], Batch [47/517], Loss: 0.2250
  Epoch [14/100], Batch [94/517], Loss: 0.3970
  Epoch [14/100], Batch [141/517], Loss: 0.2629
  Epoch [14/100], Batch [188/517], Loss: 0.4130
  Epoch [14/100], Batch [235/517], Loss: 0.4242
  Epoch [14/100], Batch [282/517], Loss: 0.4507
  Epoch [14/100], Batch [329/517], Loss: 0.2678
  Epoch [14/100], Batch [376/517], Loss: 0.4716
  Epoch [14/100], Batch [423/517], Loss: 0.2389
  Epoch [14/100], Batch [470/517], Loss: 0.3778
  Epoch [14/100], Batch [517/517], Loss: 0.4046
--- Epoch [14/100] complete. Average Training Loss: 0.3324 ---
--- Time taken for epoch: 314.27 seconds ---
  Epoch [15/100], Batch [47/517], Loss: 0.3838
  Epoch [15/100], Batch [94/517], Loss: 0.2524
  Epoch [15/100], Batch [141/517], Loss: 0.2783
  Epoch [15/100], Batch [188/517], Loss: 0.4133
  Epoch [15/100], Batch [235/517], Loss: 0.2260
  Epoch [15/100], Batch [282/517], Loss: 0.2956
  Epoch [15/100], Batch [329/517], Loss: 0.2367
  Epoch [15/100], Batch [376/517], Loss: 0.3809
  Epoch [15/100], Batch [423/517], Loss: 0.2728
  Epoch [15/100], Batch [470/517], Loss: 0.4497
  Epoch [15/100], Batch [517/517], Loss: 0.2312
--- Epoch [15/100] complete. Average Training Loss: 0.3318 ---
--- Time taken for epoch: 314.24 seconds ---
  Epoch [16/100], Batch [47/517], Loss: 0.2254
  Epoch [16/100], Batch [94/517], Loss: 0.3690
  Epoch [16/100], Batch [141/517], Loss: 0.4144
  Epoch [16/100], Batch [188/517], Loss: 0.2931
  Epoch [16/100], Batch [235/517], Loss: 0.3310
  Epoch [16/100], Batch [282/517], Loss: 0.4529
  Epoch [16/100], Batch [329/517], Loss: 0.1896
  Epoch [16/100], Batch [376/517], Loss: 0.3334
  Epoch [16/100], Batch [423/517], Loss: 0.3496
  Epoch [16/100], Batch [470/517], Loss: 0.2292
  Epoch [16/100], Batch [517/517], Loss: 0.2466
--- Epoch [16/100] complete. Average Training Loss: 0.3299 ---
--- Time taken for epoch: 314.27 seconds ---
  Epoch [17/100], Batch [47/517], Loss: 0.3988
  Epoch [17/100], Batch [94/517], Loss: 0.1533
  Epoch [17/100], Batch [141/517], Loss: 0.4225
  Epoch [17/100], Batch [188/517], Loss: 0.4594
  Epoch [17/100], Batch [235/517], Loss: 0.2446
  Epoch [17/100], Batch [282/517], Loss: 0.3455
  Epoch [17/100], Batch [329/517], Loss: 0.2456
  Epoch [17/100], Batch [376/517], Loss: 0.3825
  Epoch [17/100], Batch [423/517], Loss: 0.2224
  Epoch [17/100], Batch [470/517], Loss: 0.3377
  Epoch [17/100], Batch [517/517], Loss: 0.2051
--- Epoch [17/100] complete. Average Training Loss: 0.3289 ---
--- Time taken for epoch: 314.29 seconds ---
  Epoch [18/100], Batch [47/517], Loss: 0.3079
  Epoch [18/100], Batch [94/517], Loss: 0.3010
  Epoch [18/100], Batch [141/517], Loss: 0.3433
  Epoch [18/100], Batch [188/517], Loss: 0.1987
  Epoch [18/100], Batch [235/517], Loss: 0.2486
  Epoch [18/100], Batch [282/517], Loss: 0.4266
  Epoch [18/100], Batch [329/517], Loss: 0.4709
  Epoch [18/100], Batch [376/517], Loss: 0.4164
  Epoch [18/100], Batch [423/517], Loss: 0.4089
  Epoch [18/100], Batch [470/517], Loss: 0.3518
  Epoch [18/100], Batch [517/517], Loss: 0.4732
--- Epoch [18/100] complete. Average Training Loss: 0.3247 ---
--- Time taken for epoch: 314.06 seconds ---
  Epoch [19/100], Batch [47/517], Loss: 0.2681
  Epoch [19/100], Batch [94/517], Loss: 0.4429
  Epoch [19/100], Batch [141/517], Loss: 0.4354
  Epoch [19/100], Batch [188/517], Loss: 0.3933
  Epoch [19/100], Batch [235/517], Loss: 0.3981
  Epoch [19/100], Batch [282/517], Loss: 0.4661
  Epoch [19/100], Batch [329/517], Loss: 0.3902
  Epoch [19/100], Batch [376/517], Loss: 0.4123
  Epoch [19/100], Batch [423/517], Loss: 0.2769
  Epoch [19/100], Batch [470/517], Loss: 0.3013
  Epoch [19/100], Batch [517/517], Loss: 0.3889
--- Epoch [19/100] complete. Average Training Loss: 0.3253 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [20/100], Batch [47/517], Loss: 0.2394
  Epoch [20/100], Batch [94/517], Loss: 0.4387
  Epoch [20/100], Batch [141/517], Loss: 0.2724
  Epoch [20/100], Batch [188/517], Loss: 0.3993
  Epoch [20/100], Batch [235/517], Loss: 0.4043
  Epoch [20/100], Batch [282/517], Loss: 0.3149
  Epoch [20/100], Batch [329/517], Loss: 0.4462
  Epoch [20/100], Batch [376/517], Loss: 0.3385
  Epoch [20/100], Batch [423/517], Loss: 0.3265
  Epoch [20/100], Batch [470/517], Loss: 0.3888
  Epoch [20/100], Batch [517/517], Loss: 0.3766
--- Epoch [20/100] complete. Average Training Loss: 0.3206 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [21/100], Batch [47/517], Loss: 0.2743
  Epoch [21/100], Batch [94/517], Loss: 0.3227
  Epoch [21/100], Batch [141/517], Loss: 0.3824
  Epoch [21/100], Batch [188/517], Loss: 0.3433
  Epoch [21/100], Batch [235/517], Loss: 0.2060
  Epoch [21/100], Batch [282/517], Loss: 0.3370
  Epoch [21/100], Batch [329/517], Loss: 0.3259
  Epoch [21/100], Batch [376/517], Loss: 0.2299
  Epoch [21/100], Batch [423/517], Loss: 0.3264
  Epoch [21/100], Batch [470/517], Loss: 0.3588
  Epoch [21/100], Batch [517/517], Loss: 0.3988
--- Epoch [21/100] complete. Average Training Loss: 0.3217 ---
--- Time taken for epoch: 314.15 seconds ---
  Epoch [22/100], Batch [47/517], Loss: 0.2248
  Epoch [22/100], Batch [94/517], Loss: 0.1600
  Epoch [22/100], Batch [141/517], Loss: 0.2613
  Epoch [22/100], Batch [188/517], Loss: 0.1369
  Epoch [22/100], Batch [235/517], Loss: 0.2214
  Epoch [22/100], Batch [282/517], Loss: 0.3960
  Epoch [22/100], Batch [329/517], Loss: 0.3404
  Epoch [22/100], Batch [376/517], Loss: 0.2561
  Epoch [22/100], Batch [423/517], Loss: 0.2388
  Epoch [22/100], Batch [470/517], Loss: 0.4192
  Epoch [22/100], Batch [517/517], Loss: 0.3520
--- Epoch [22/100] complete. Average Training Loss: 0.3116 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [23/100], Batch [47/517], Loss: 0.2561
  Epoch [23/100], Batch [94/517], Loss: 0.3635
  Epoch [23/100], Batch [141/517], Loss: 0.2195
  Epoch [23/100], Batch [188/517], Loss: 0.4116
  Epoch [23/100], Batch [235/517], Loss: 0.3218
  Epoch [23/100], Batch [282/517], Loss: 0.1951
  Epoch [23/100], Batch [329/517], Loss: 0.3792
  Epoch [23/100], Batch [376/517], Loss: 0.3966
  Epoch [23/100], Batch [423/517], Loss: 0.2083
  Epoch [23/100], Batch [470/517], Loss: 0.3309
  Epoch [23/100], Batch [517/517], Loss: 0.4283
--- Epoch [23/100] complete. Average Training Loss: 0.3070 ---
--- Time taken for epoch: 314.02 seconds ---
  Epoch [24/100], Batch [47/517], Loss: 0.2829
  Epoch [24/100], Batch [94/517], Loss: 0.1578
  Epoch [24/100], Batch [141/517], Loss: 0.2983
  Epoch [24/100], Batch [188/517], Loss: 0.3527
  Epoch [24/100], Batch [235/517], Loss: 0.4370
  Epoch [24/100], Batch [282/517], Loss: 0.2070
  Epoch [24/100], Batch [329/517], Loss: 0.2641
  Epoch [24/100], Batch [376/517], Loss: 0.4387
  Epoch [24/100], Batch [423/517], Loss: 0.1924
  Epoch [24/100], Batch [470/517], Loss: 0.3224
  Epoch [24/100], Batch [517/517], Loss: 0.3837
--- Epoch [24/100] complete. Average Training Loss: 0.3128 ---
--- Time taken for epoch: 314.11 seconds ---
  Epoch [25/100], Batch [47/517], Loss: 0.3911
  Epoch [25/100], Batch [94/517], Loss: 0.4382
  Epoch [25/100], Batch [141/517], Loss: 0.4271
  Epoch [25/100], Batch [188/517], Loss: 0.2378
  Epoch [25/100], Batch [235/517], Loss: 0.3449
  Epoch [25/100], Batch [282/517], Loss: 0.3654
  Epoch [25/100], Batch [329/517], Loss: 0.4191
  Epoch [25/100], Batch [376/517], Loss: 0.1956
  Epoch [25/100], Batch [423/517], Loss: 0.3086
  Epoch [25/100], Batch [470/517], Loss: 0.3114
  Epoch [25/100], Batch [517/517], Loss: 0.2070
--- Epoch [25/100] complete. Average Training Loss: 0.3067 ---
--- Time taken for epoch: 314.16 seconds ---
 -- Updated Checkpoint: Saved model at 25 epochs.
  Epoch [26/100], Batch [47/517], Loss: 0.1621
  Epoch [26/100], Batch [94/517], Loss: 0.2460
  Epoch [26/100], Batch [141/517], Loss: 0.2323
  Epoch [26/100], Batch [188/517], Loss: 0.2784
  Epoch [26/100], Batch [235/517], Loss: 0.2449
  Epoch [26/100], Batch [282/517], Loss: 0.4163
  Epoch [26/100], Batch [329/517], Loss: 0.3715
  Epoch [26/100], Batch [376/517], Loss: 0.1768
  Epoch [26/100], Batch [423/517], Loss: 0.1732
  Epoch [26/100], Batch [470/517], Loss: 0.3815
  Epoch [26/100], Batch [517/517], Loss: 0.1087
--- Epoch [26/100] complete. Average Training Loss: 0.3035 ---
--- Time taken for epoch: 314.15 seconds ---
  Epoch [27/100], Batch [47/517], Loss: 0.1765
  Epoch [27/100], Batch [94/517], Loss: 0.2271
  Epoch [27/100], Batch [141/517], Loss: 0.4043
  Epoch [27/100], Batch [188/517], Loss: 0.2595
  Epoch [27/100], Batch [235/517], Loss: 0.2176
  Epoch [27/100], Batch [282/517], Loss: 0.3489
  Epoch [27/100], Batch [329/517], Loss: 0.1382
  Epoch [27/100], Batch [376/517], Loss: 0.3975
  Epoch [27/100], Batch [423/517], Loss: 0.3983
  Epoch [27/100], Batch [470/517], Loss: 0.2008
  Epoch [27/100], Batch [517/517], Loss: 0.2975
--- Epoch [27/100] complete. Average Training Loss: 0.2978 ---
--- Time taken for epoch: 314.13 seconds ---
  Epoch [28/100], Batch [47/517], Loss: 0.2757
  Epoch [28/100], Batch [94/517], Loss: 0.2865
  Epoch [28/100], Batch [141/517], Loss: 0.2324
  Epoch [28/100], Batch [188/517], Loss: 0.1969
  Epoch [28/100], Batch [235/517], Loss: 0.1978
  Epoch [28/100], Batch [282/517], Loss: 0.1587
  Epoch [28/100], Batch [329/517], Loss: 0.3909
  Epoch [28/100], Batch [376/517], Loss: 0.2492
  Epoch [28/100], Batch [423/517], Loss: 0.2609
  Epoch [28/100], Batch [470/517], Loss: 0.3554
  Epoch [28/100], Batch [517/517], Loss: 0.2931
--- Epoch [28/100] complete. Average Training Loss: 0.2931 ---
--- Time taken for epoch: 314.15 seconds ---
  Epoch [29/100], Batch [47/517], Loss: 0.2128
  Epoch [29/100], Batch [94/517], Loss: 0.1591
  Epoch [29/100], Batch [141/517], Loss: 0.4304
  Epoch [29/100], Batch [188/517], Loss: 0.2939
  Epoch [29/100], Batch [235/517], Loss: 0.2093
  Epoch [29/100], Batch [282/517], Loss: 0.2870
  Epoch [29/100], Batch [329/517], Loss: 0.3459
  Epoch [29/100], Batch [376/517], Loss: 0.3227
  Epoch [29/100], Batch [423/517], Loss: 0.1984
  Epoch [29/100], Batch [470/517], Loss: 0.3672
  Epoch [29/100], Batch [517/517], Loss: 0.2334
--- Epoch [29/100] complete. Average Training Loss: 0.2945 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [30/100], Batch [47/517], Loss: 0.3034
  Epoch [30/100], Batch [94/517], Loss: 0.4488
  Epoch [30/100], Batch [141/517], Loss: 0.4039
  Epoch [30/100], Batch [188/517], Loss: 0.2554
  Epoch [30/100], Batch [235/517], Loss: 0.2383
  Epoch [30/100], Batch [282/517], Loss: 0.2046
  Epoch [30/100], Batch [329/517], Loss: 0.1774
  Epoch [30/100], Batch [376/517], Loss: 0.1672
  Epoch [30/100], Batch [423/517], Loss: 0.4145
  Epoch [30/100], Batch [470/517], Loss: 0.3716
  Epoch [30/100], Batch [517/517], Loss: 0.4182
--- Epoch [30/100] complete. Average Training Loss: 0.2922 ---
--- Time taken for epoch: 314.24 seconds ---
  Epoch [31/100], Batch [47/517], Loss: 0.3834
  Epoch [31/100], Batch [94/517], Loss: 0.2838
  Epoch [31/100], Batch [141/517], Loss: 0.1914
  Epoch [31/100], Batch [188/517], Loss: 0.3914
  Epoch [31/100], Batch [235/517], Loss: 0.2392
  Epoch [31/100], Batch [282/517], Loss: 0.1614
  Epoch [31/100], Batch [329/517], Loss: 0.3475
  Epoch [31/100], Batch [376/517], Loss: 0.3886
  Epoch [31/100], Batch [423/517], Loss: 0.2769
  Epoch [31/100], Batch [470/517], Loss: 0.4220
  Epoch [31/100], Batch [517/517], Loss: 0.2130
--- Epoch [31/100] complete. Average Training Loss: 0.2908 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [32/100], Batch [47/517], Loss: 0.3754
  Epoch [32/100], Batch [94/517], Loss: 0.2337
  Epoch [32/100], Batch [141/517], Loss: 0.1747
  Epoch [32/100], Batch [188/517], Loss: 0.4081
  Epoch [32/100], Batch [235/517], Loss: 0.4220
  Epoch [32/100], Batch [282/517], Loss: 0.2376
  Epoch [32/100], Batch [329/517], Loss: 0.4213
  Epoch [32/100], Batch [376/517], Loss: 0.4081
  Epoch [32/100], Batch [423/517], Loss: 0.1979
  Epoch [32/100], Batch [470/517], Loss: 0.1329
  Epoch [32/100], Batch [517/517], Loss: 0.2912
--- Epoch [32/100] complete. Average Training Loss: 0.2851 ---
--- Time taken for epoch: 314.17 seconds ---
  Epoch [33/100], Batch [47/517], Loss: 0.3446
  Epoch [33/100], Batch [94/517], Loss: 0.2416
  Epoch [33/100], Batch [141/517], Loss: 0.4235
  Epoch [33/100], Batch [188/517], Loss: 0.1816
  Epoch [33/100], Batch [235/517], Loss: 0.4055
  Epoch [33/100], Batch [282/517], Loss: 0.1644
  Epoch [33/100], Batch [329/517], Loss: 0.3933
  Epoch [33/100], Batch [376/517], Loss: 0.2708
  Epoch [33/100], Batch [423/517], Loss: 0.2508
  Epoch [33/100], Batch [470/517], Loss: 0.1748
  Epoch [33/100], Batch [517/517], Loss: 0.3492
--- Epoch [33/100] complete. Average Training Loss: 0.2874 ---
--- Time taken for epoch: 314.16 seconds ---
  Epoch [34/100], Batch [47/517], Loss: 0.1823
  Epoch [34/100], Batch [94/517], Loss: 0.1980
  Epoch [34/100], Batch [141/517], Loss: 0.2024
  Epoch [34/100], Batch [188/517], Loss: 0.1023
  Epoch [34/100], Batch [235/517], Loss: 0.1605
  Epoch [34/100], Batch [282/517], Loss: 0.2310
  Epoch [34/100], Batch [329/517], Loss: 0.3300
  Epoch [34/100], Batch [376/517], Loss: 0.1835
  Epoch [34/100], Batch [423/517], Loss: 0.2709
  Epoch [34/100], Batch [470/517], Loss: 0.3567
  Epoch [34/100], Batch [517/517], Loss: 0.4044
--- Epoch [34/100] complete. Average Training Loss: 0.2835 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [35/100], Batch [47/517], Loss: 0.1971
  Epoch [35/100], Batch [94/517], Loss: 0.2012
  Epoch [35/100], Batch [141/517], Loss: 0.2305
  Epoch [35/100], Batch [188/517], Loss: 0.1429
  Epoch [35/100], Batch [235/517], Loss: 0.2736
  Epoch [35/100], Batch [282/517], Loss: 0.3959
  Epoch [35/100], Batch [329/517], Loss: 0.1042
  Epoch [35/100], Batch [376/517], Loss: 0.3010
  Epoch [35/100], Batch [423/517], Loss: 0.2667
  Epoch [35/100], Batch [470/517], Loss: 0.3071
  Epoch [35/100], Batch [517/517], Loss: 0.4063
--- Epoch [35/100] complete. Average Training Loss: 0.2889 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [36/100], Batch [47/517], Loss: 0.2338
  Epoch [36/100], Batch [94/517], Loss: 0.2645
  Epoch [36/100], Batch [141/517], Loss: 0.2185
  Epoch [36/100], Batch [188/517], Loss: 0.2623
  Epoch [36/100], Batch [235/517], Loss: 0.1880
  Epoch [36/100], Batch [282/517], Loss: 0.4590
  Epoch [36/100], Batch [329/517], Loss: 0.2366
  Epoch [36/100], Batch [376/517], Loss: 0.2571
  Epoch [36/100], Batch [423/517], Loss: 0.1801
  Epoch [36/100], Batch [470/517], Loss: 0.2812
  Epoch [36/100], Batch [517/517], Loss: 0.2095
--- Epoch [36/100] complete. Average Training Loss: 0.2912 ---
--- Time taken for epoch: 314.32 seconds ---
  Epoch [37/100], Batch [47/517], Loss: 0.3126
  Epoch [37/100], Batch [94/517], Loss: 0.2267
  Epoch [37/100], Batch [141/517], Loss: 0.3043
  Epoch [37/100], Batch [188/517], Loss: 0.1961
  Epoch [37/100], Batch [235/517], Loss: 0.1949
  Epoch [37/100], Batch [282/517], Loss: 0.3900
  Epoch [37/100], Batch [329/517], Loss: 0.4072
  Epoch [37/100], Batch [376/517], Loss: 0.3634
  Epoch [37/100], Batch [423/517], Loss: 0.3111
  Epoch [37/100], Batch [470/517], Loss: 0.4045
  Epoch [37/100], Batch [517/517], Loss: 0.1819
--- Epoch [37/100] complete. Average Training Loss: 0.2750 ---
--- Time taken for epoch: 314.24 seconds ---
  Epoch [38/100], Batch [47/517], Loss: 0.2182
  Epoch [38/100], Batch [94/517], Loss: 0.2324
  Epoch [38/100], Batch [141/517], Loss: 0.2428
  Epoch [38/100], Batch [188/517], Loss: 0.2426
  Epoch [38/100], Batch [235/517], Loss: 0.2841
  Epoch [38/100], Batch [282/517], Loss: 0.1806
  Epoch [38/100], Batch [329/517], Loss: 0.4302
  Epoch [38/100], Batch [376/517], Loss: 0.2548
  Epoch [38/100], Batch [423/517], Loss: 0.4468
  Epoch [38/100], Batch [470/517], Loss: 0.3539
  Epoch [38/100], Batch [517/517], Loss: 0.3020
--- Epoch [38/100] complete. Average Training Loss: 0.2786 ---
--- Time taken for epoch: 314.16 seconds ---
  Epoch [39/100], Batch [47/517], Loss: 0.3050
  Epoch [39/100], Batch [94/517], Loss: 0.1579
  Epoch [39/100], Batch [141/517], Loss: 0.2042
  Epoch [39/100], Batch [188/517], Loss: 0.2522
  Epoch [39/100], Batch [235/517], Loss: 0.2364
  Epoch [39/100], Batch [282/517], Loss: 0.1641
  Epoch [39/100], Batch [329/517], Loss: 0.4104
  Epoch [39/100], Batch [376/517], Loss: 0.1165
  Epoch [39/100], Batch [423/517], Loss: 0.4034
  Epoch [39/100], Batch [470/517], Loss: 0.3905
  Epoch [39/100], Batch [517/517], Loss: 0.4268
--- Epoch [39/100] complete. Average Training Loss: 0.2795 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [40/100], Batch [47/517], Loss: 0.2973
  Epoch [40/100], Batch [94/517], Loss: 0.3867
  Epoch [40/100], Batch [141/517], Loss: 0.2319
  Epoch [40/100], Batch [188/517], Loss: 0.2973
  Epoch [40/100], Batch [235/517], Loss: 0.1857
  Epoch [40/100], Batch [282/517], Loss: 0.3292
  Epoch [40/100], Batch [329/517], Loss: 0.3863
  Epoch [40/100], Batch [376/517], Loss: 0.2650
  Epoch [40/100], Batch [423/517], Loss: 0.3715
  Epoch [40/100], Batch [470/517], Loss: 0.4167
  Epoch [40/100], Batch [517/517], Loss: 0.1570
--- Epoch [40/100] complete. Average Training Loss: 0.2719 ---
--- Time taken for epoch: 314.28 seconds ---
  Epoch [41/100], Batch [47/517], Loss: 0.2481
  Epoch [41/100], Batch [94/517], Loss: 0.3759
  Epoch [41/100], Batch [141/517], Loss: 0.3966
  Epoch [41/100], Batch [188/517], Loss: 0.3967
  Epoch [41/100], Batch [235/517], Loss: 0.2372
  Epoch [41/100], Batch [282/517], Loss: 0.1366
  Epoch [41/100], Batch [329/517], Loss: 0.2599
  Epoch [41/100], Batch [376/517], Loss: 0.4175
  Epoch [41/100], Batch [423/517], Loss: 0.2658
  Epoch [41/100], Batch [470/517], Loss: 0.2755
  Epoch [41/100], Batch [517/517], Loss: 0.3799
--- Epoch [41/100] complete. Average Training Loss: 0.2725 ---
--- Time taken for epoch: 314.29 seconds ---
  Epoch [42/100], Batch [47/517], Loss: 0.1916
  Epoch [42/100], Batch [94/517], Loss: 0.1309
  Epoch [42/100], Batch [141/517], Loss: 0.3191
  Epoch [42/100], Batch [188/517], Loss: 0.1944
  Epoch [42/100], Batch [235/517], Loss: 0.2436
  Epoch [42/100], Batch [282/517], Loss: 0.2327
  Epoch [42/100], Batch [329/517], Loss: 0.1972
  Epoch [42/100], Batch [376/517], Loss: 0.2139
  Epoch [42/100], Batch [423/517], Loss: 0.4030
  Epoch [42/100], Batch [470/517], Loss: 0.1929
  Epoch [42/100], Batch [517/517], Loss: 0.1859
--- Epoch [42/100] complete. Average Training Loss: 0.2742 ---
--- Time taken for epoch: 314.16 seconds ---
  Epoch [43/100], Batch [47/517], Loss: 0.3930
  Epoch [43/100], Batch [94/517], Loss: 0.1895
  Epoch [43/100], Batch [141/517], Loss: 0.3943
  Epoch [43/100], Batch [188/517], Loss: 0.1980
  Epoch [43/100], Batch [235/517], Loss: 0.4110
  Epoch [43/100], Batch [282/517], Loss: 0.1695
  Epoch [43/100], Batch [329/517], Loss: 0.1386
  Epoch [43/100], Batch [376/517], Loss: 0.4146
  Epoch [43/100], Batch [423/517], Loss: 0.3496
  Epoch [43/100], Batch [470/517], Loss: 0.1005
  Epoch [43/100], Batch [517/517], Loss: 0.1704
--- Epoch [43/100] complete. Average Training Loss: 0.2750 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [44/100], Batch [47/517], Loss: 0.1166
  Epoch [44/100], Batch [94/517], Loss: 0.2135
  Epoch [44/100], Batch [141/517], Loss: 0.1702
  Epoch [44/100], Batch [188/517], Loss: 0.1516
  Epoch [44/100], Batch [235/517], Loss: 0.2926
  Epoch [44/100], Batch [282/517], Loss: 0.4032
  Epoch [44/100], Batch [329/517], Loss: 0.1910
  Epoch [44/100], Batch [376/517], Loss: 0.2826
  Epoch [44/100], Batch [423/517], Loss: 0.2291
  Epoch [44/100], Batch [470/517], Loss: 0.2427
  Epoch [44/100], Batch [517/517], Loss: 0.3949
--- Epoch [44/100] complete. Average Training Loss: 0.2729 ---
--- Time taken for epoch: 314.07 seconds ---
  Epoch [45/100], Batch [47/517], Loss: 0.1691
  Epoch [45/100], Batch [94/517], Loss: 0.1952
  Epoch [45/100], Batch [141/517], Loss: 0.1779
  Epoch [45/100], Batch [188/517], Loss: 0.1936
  Epoch [45/100], Batch [235/517], Loss: 0.4000
  Epoch [45/100], Batch [282/517], Loss: 0.1313
  Epoch [45/100], Batch [329/517], Loss: 0.1077
  Epoch [45/100], Batch [376/517], Loss: 0.1903
  Epoch [45/100], Batch [423/517], Loss: 0.1985
  Epoch [45/100], Batch [470/517], Loss: 0.1804
  Epoch [45/100], Batch [517/517], Loss: 0.3743
--- Epoch [45/100] complete. Average Training Loss: 0.2656 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [46/100], Batch [47/517], Loss: 0.1342
  Epoch [46/100], Batch [94/517], Loss: 0.2041
  Epoch [46/100], Batch [141/517], Loss: 0.2273
  Epoch [46/100], Batch [188/517], Loss: 0.1200
  Epoch [46/100], Batch [235/517], Loss: 0.2048
  Epoch [46/100], Batch [282/517], Loss: 0.2252
  Epoch [46/100], Batch [329/517], Loss: 0.2339
  Epoch [46/100], Batch [376/517], Loss: 0.1196
  Epoch [46/100], Batch [423/517], Loss: 0.0979
  Epoch [46/100], Batch [470/517], Loss: 0.2121
  Epoch [46/100], Batch [517/517], Loss: 0.4512
--- Epoch [46/100] complete. Average Training Loss: 0.2627 ---
--- Time taken for epoch: 314.12 seconds ---
  Epoch [47/100], Batch [47/517], Loss: 0.4253
  Epoch [47/100], Batch [94/517], Loss: 0.4118
  Epoch [47/100], Batch [141/517], Loss: 0.2170
  Epoch [47/100], Batch [188/517], Loss: 0.1898
  Epoch [47/100], Batch [235/517], Loss: 0.1186
  Epoch [47/100], Batch [282/517], Loss: 0.2427
  Epoch [47/100], Batch [329/517], Loss: 0.2582
  Epoch [47/100], Batch [376/517], Loss: 0.3929
  Epoch [47/100], Batch [423/517], Loss: 0.2286
  Epoch [47/100], Batch [470/517], Loss: 0.2811
  Epoch [47/100], Batch [517/517], Loss: 0.1273
--- Epoch [47/100] complete. Average Training Loss: 0.2661 ---
--- Time taken for epoch: 314.13 seconds ---
  Epoch [48/100], Batch [47/517], Loss: 0.4030
  Epoch [48/100], Batch [94/517], Loss: 0.3365
  Epoch [48/100], Batch [141/517], Loss: 0.1973
  Epoch [48/100], Batch [188/517], Loss: 0.3927
  Epoch [48/100], Batch [235/517], Loss: 0.2209
  Epoch [48/100], Batch [282/517], Loss: 0.4007
  Epoch [48/100], Batch [329/517], Loss: 0.2427
  Epoch [48/100], Batch [376/517], Loss: 0.1424
  Epoch [48/100], Batch [423/517], Loss: 0.3883
  Epoch [48/100], Batch [470/517], Loss: 0.2704
  Epoch [48/100], Batch [517/517], Loss: 0.1383
--- Epoch [48/100] complete. Average Training Loss: 0.2611 ---
--- Time taken for epoch: 314.11 seconds ---
  Epoch [49/100], Batch [47/517], Loss: 0.3938
  Epoch [49/100], Batch [94/517], Loss: 0.4067
  Epoch [49/100], Batch [141/517], Loss: 0.3548
  Epoch [49/100], Batch [188/517], Loss: 0.1815
  Epoch [49/100], Batch [235/517], Loss: 0.1902
  Epoch [49/100], Batch [282/517], Loss: 0.3968
  Epoch [49/100], Batch [329/517], Loss: 0.2599
  Epoch [49/100], Batch [376/517], Loss: 0.3957
  Epoch [49/100], Batch [423/517], Loss: 0.2789
  Epoch [49/100], Batch [470/517], Loss: 0.1775
  Epoch [49/100], Batch [517/517], Loss: 0.3480
--- Epoch [49/100] complete. Average Training Loss: 0.2571 ---
--- Time taken for epoch: 314.12 seconds ---
  Epoch [50/100], Batch [47/517], Loss: 0.2060
  Epoch [50/100], Batch [94/517], Loss: 0.4039
  Epoch [50/100], Batch [141/517], Loss: 0.4028
  Epoch [50/100], Batch [188/517], Loss: 0.2735
  Epoch [50/100], Batch [235/517], Loss: 0.4020
  Epoch [50/100], Batch [282/517], Loss: 0.2752
  Epoch [50/100], Batch [329/517], Loss: 0.2084
  Epoch [50/100], Batch [376/517], Loss: 0.2810
  Epoch [50/100], Batch [423/517], Loss: 0.2922
  Epoch [50/100], Batch [470/517], Loss: 0.1164
  Epoch [50/100], Batch [517/517], Loss: 0.3984
--- Epoch [50/100] complete. Average Training Loss: 0.2607 ---
--- Time taken for epoch: 314.02 seconds ---
 -- Updated Checkpoint: Saved model at 50 epochs.
  Epoch [51/100], Batch [47/517], Loss: 0.4121
  Epoch [51/100], Batch [94/517], Loss: 0.3048
  Epoch [51/100], Batch [141/517], Loss: 0.3924
  Epoch [51/100], Batch [188/517], Loss: 0.2686
  Epoch [51/100], Batch [235/517], Loss: 0.2709
  Epoch [51/100], Batch [282/517], Loss: 0.1366
  Epoch [51/100], Batch [329/517], Loss: 0.4408
  Epoch [51/100], Batch [376/517], Loss: 0.4010
  Epoch [51/100], Batch [423/517], Loss: 0.3763
  Epoch [51/100], Batch [470/517], Loss: 0.2000
  Epoch [51/100], Batch [517/517], Loss: 0.1892
--- Epoch [51/100] complete. Average Training Loss: 0.2585 ---
--- Time taken for epoch: 314.13 seconds ---
  Epoch [52/100], Batch [47/517], Loss: 0.1820
  Epoch [52/100], Batch [94/517], Loss: 0.2715
  Epoch [52/100], Batch [141/517], Loss: 0.1662
  Epoch [52/100], Batch [188/517], Loss: 0.3831
  Epoch [52/100], Batch [235/517], Loss: 0.3360
  Epoch [52/100], Batch [282/517], Loss: 0.2153
  Epoch [52/100], Batch [329/517], Loss: 0.2140
  Epoch [52/100], Batch [376/517], Loss: 0.2664
  Epoch [52/100], Batch [423/517], Loss: 0.1335
  Epoch [52/100], Batch [470/517], Loss: 0.2304
  Epoch [52/100], Batch [517/517], Loss: 0.3930
--- Epoch [52/100] complete. Average Training Loss: 0.2612 ---
--- Time taken for epoch: 314.03 seconds ---
  Epoch [53/100], Batch [47/517], Loss: 0.1803
  Epoch [53/100], Batch [94/517], Loss: 0.3302
  Epoch [53/100], Batch [141/517], Loss: 0.2367
  Epoch [53/100], Batch [188/517], Loss: 0.2468
  Epoch [53/100], Batch [235/517], Loss: 0.2580
  Epoch [53/100], Batch [282/517], Loss: 0.3990
  Epoch [53/100], Batch [329/517], Loss: 0.1374
  Epoch [53/100], Batch [376/517], Loss: 0.1941
  Epoch [53/100], Batch [423/517], Loss: 0.3860
  Epoch [53/100], Batch [470/517], Loss: 0.2057
  Epoch [53/100], Batch [517/517], Loss: 0.3005
--- Epoch [53/100] complete. Average Training Loss: 0.2551 ---
--- Time taken for epoch: 314.06 seconds ---
  Epoch [54/100], Batch [47/517], Loss: 0.4160
  Epoch [54/100], Batch [94/517], Loss: 0.2199
  Epoch [54/100], Batch [141/517], Loss: 0.1706
  Epoch [54/100], Batch [188/517], Loss: 0.2643
  Epoch [54/100], Batch [235/517], Loss: 0.3422
  Epoch [54/100], Batch [282/517], Loss: 0.1598
  Epoch [54/100], Batch [329/517], Loss: 0.2381
  Epoch [54/100], Batch [376/517], Loss: 0.3621
  Epoch [54/100], Batch [423/517], Loss: 0.2685
  Epoch [54/100], Batch [470/517], Loss: 0.3942
  Epoch [54/100], Batch [517/517], Loss: 0.2251
--- Epoch [54/100] complete. Average Training Loss: 0.2618 ---
--- Time taken for epoch: 314.27 seconds ---
  Epoch [55/100], Batch [47/517], Loss: 0.2525
  Epoch [55/100], Batch [94/517], Loss: 0.1402
  Epoch [55/100], Batch [141/517], Loss: 0.4517
  Epoch [55/100], Batch [188/517], Loss: 0.2610
  Epoch [55/100], Batch [235/517], Loss: 0.4210
  Epoch [55/100], Batch [282/517], Loss: 0.3848
  Epoch [55/100], Batch [329/517], Loss: 0.1403
  Epoch [55/100], Batch [376/517], Loss: 0.2780
  Epoch [55/100], Batch [423/517], Loss: 0.1653
  Epoch [55/100], Batch [470/517], Loss: 0.1109
  Epoch [55/100], Batch [517/517], Loss: 0.3754
--- Epoch [55/100] complete. Average Training Loss: 0.2663 ---
--- Time taken for epoch: 314.18 seconds ---
  Epoch [56/100], Batch [47/517], Loss: 0.2398
  Epoch [56/100], Batch [94/517], Loss: 0.1397
  Epoch [56/100], Batch [141/517], Loss: 0.2021
  Epoch [56/100], Batch [188/517], Loss: 0.2614
  Epoch [56/100], Batch [235/517], Loss: 0.2999
  Epoch [56/100], Batch [282/517], Loss: 0.1530
  Epoch [56/100], Batch [329/517], Loss: 0.3966
  Epoch [56/100], Batch [376/517], Loss: 0.2301
  Epoch [56/100], Batch [423/517], Loss: 0.3884
  Epoch [56/100], Batch [470/517], Loss: 0.2222
  Epoch [56/100], Batch [517/517], Loss: 0.1289
--- Epoch [56/100] complete. Average Training Loss: 0.2514 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [57/100], Batch [47/517], Loss: 0.1818
  Epoch [57/100], Batch [94/517], Loss: 0.1756
  Epoch [57/100], Batch [141/517], Loss: 0.2038
  Epoch [57/100], Batch [188/517], Loss: 0.3200
  Epoch [57/100], Batch [235/517], Loss: 0.4138
  Epoch [57/100], Batch [282/517], Loss: 0.2852
  Epoch [57/100], Batch [329/517], Loss: 0.1316
  Epoch [57/100], Batch [376/517], Loss: 0.1923
  Epoch [57/100], Batch [423/517], Loss: 0.4032
  Epoch [57/100], Batch [470/517], Loss: 0.2270
  Epoch [57/100], Batch [517/517], Loss: 0.1522
--- Epoch [57/100] complete. Average Training Loss: 0.2587 ---
--- Time taken for epoch: 314.19 seconds ---
  Epoch [58/100], Batch [47/517], Loss: 0.4012
  Epoch [58/100], Batch [94/517], Loss: 0.1289
  Epoch [58/100], Batch [141/517], Loss: 0.2678
  Epoch [58/100], Batch [188/517], Loss: 0.3138
  Epoch [58/100], Batch [235/517], Loss: 0.1735
  Epoch [58/100], Batch [282/517], Loss: 0.2148
  Epoch [58/100], Batch [329/517], Loss: 0.3066
  Epoch [58/100], Batch [376/517], Loss: 0.3562
  Epoch [58/100], Batch [423/517], Loss: 0.1915
  Epoch [58/100], Batch [470/517], Loss: 0.4002
  Epoch [58/100], Batch [517/517], Loss: 0.4386
--- Epoch [58/100] complete. Average Training Loss: 0.2584 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [59/100], Batch [47/517], Loss: 0.1862
  Epoch [59/100], Batch [94/517], Loss: 0.1604
  Epoch [59/100], Batch [141/517], Loss: 0.1820
  Epoch [59/100], Batch [188/517], Loss: 0.1783
  Epoch [59/100], Batch [235/517], Loss: 0.1392
  Epoch [59/100], Batch [282/517], Loss: 0.1342
  Epoch [59/100], Batch [329/517], Loss: 0.1711
  Epoch [59/100], Batch [376/517], Loss: 0.1940
  Epoch [59/100], Batch [423/517], Loss: 0.2056
  Epoch [59/100], Batch [470/517], Loss: 0.1785
  Epoch [59/100], Batch [517/517], Loss: 0.2574
--- Epoch [59/100] complete. Average Training Loss: 0.2514 ---
--- Time taken for epoch: 314.05 seconds ---
  Epoch [60/100], Batch [47/517], Loss: 0.2331
  Epoch [60/100], Batch [94/517], Loss: 0.2021
  Epoch [60/100], Batch [141/517], Loss: 0.4481
  Epoch [60/100], Batch [188/517], Loss: 0.1244
  Epoch [60/100], Batch [235/517], Loss: 0.2037
  Epoch [60/100], Batch [282/517], Loss: 0.1946
  Epoch [60/100], Batch [329/517], Loss: 0.1460
  Epoch [60/100], Batch [376/517], Loss: 0.1349
  Epoch [60/100], Batch [423/517], Loss: 0.3965
  Epoch [60/100], Batch [470/517], Loss: 0.2275
  Epoch [60/100], Batch [517/517], Loss: 0.4271
--- Epoch [60/100] complete. Average Training Loss: 0.2516 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [61/100], Batch [47/517], Loss: 0.2238
  Epoch [61/100], Batch [94/517], Loss: 0.2282
  Epoch [61/100], Batch [141/517], Loss: 0.1754
  Epoch [61/100], Batch [188/517], Loss: 0.0657
  Epoch [61/100], Batch [235/517], Loss: 0.1734
  Epoch [61/100], Batch [282/517], Loss: 0.1411
  Epoch [61/100], Batch [329/517], Loss: 0.3891
  Epoch [61/100], Batch [376/517], Loss: 0.4058
  Epoch [61/100], Batch [423/517], Loss: 0.3982
  Epoch [61/100], Batch [470/517], Loss: 0.2325
  Epoch [61/100], Batch [517/517], Loss: 0.2275
--- Epoch [61/100] complete. Average Training Loss: 0.2500 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [62/100], Batch [47/517], Loss: 0.2979
  Epoch [62/100], Batch [94/517], Loss: 0.2204
  Epoch [62/100], Batch [141/517], Loss: 0.2095
  Epoch [62/100], Batch [188/517], Loss: 0.1818
  Epoch [62/100], Batch [235/517], Loss: 0.1440
  Epoch [62/100], Batch [282/517], Loss: 0.2846
  Epoch [62/100], Batch [329/517], Loss: 0.1361
  Epoch [62/100], Batch [376/517], Loss: 0.4013
  Epoch [62/100], Batch [423/517], Loss: 0.2013
  Epoch [62/100], Batch [470/517], Loss: 0.4112
  Epoch [62/100], Batch [517/517], Loss: 0.2397
--- Epoch [62/100] complete. Average Training Loss: 0.2568 ---
--- Time taken for epoch: 314.24 seconds ---
  Epoch [63/100], Batch [47/517], Loss: 0.2103
  Epoch [63/100], Batch [94/517], Loss: 0.1931
  Epoch [63/100], Batch [141/517], Loss: 0.4129
  Epoch [63/100], Batch [188/517], Loss: 0.1293
  Epoch [63/100], Batch [235/517], Loss: 0.1698
  Epoch [63/100], Batch [282/517], Loss: 0.2824
  Epoch [63/100], Batch [329/517], Loss: 0.3864
  Epoch [63/100], Batch [376/517], Loss: 0.1876
  Epoch [63/100], Batch [423/517], Loss: 0.1458
  Epoch [63/100], Batch [470/517], Loss: 0.1693
  Epoch [63/100], Batch [517/517], Loss: 0.2181
--- Epoch [63/100] complete. Average Training Loss: 0.2494 ---
--- Time taken for epoch: 314.17 seconds ---
  Epoch [64/100], Batch [47/517], Loss: 0.2116
  Epoch [64/100], Batch [94/517], Loss: 0.2429
  Epoch [64/100], Batch [141/517], Loss: 0.1945
  Epoch [64/100], Batch [188/517], Loss: 0.2884
  Epoch [64/100], Batch [235/517], Loss: 0.1908
  Epoch [64/100], Batch [282/517], Loss: 0.1382
  Epoch [64/100], Batch [329/517], Loss: 0.1656
  Epoch [64/100], Batch [376/517], Loss: 0.4593
  Epoch [64/100], Batch [423/517], Loss: 0.1853
  Epoch [64/100], Batch [470/517], Loss: 0.1423
  Epoch [64/100], Batch [517/517], Loss: 0.1246
--- Epoch [64/100] complete. Average Training Loss: 0.2473 ---
--- Time taken for epoch: 314.04 seconds ---
  Epoch [65/100], Batch [47/517], Loss: 0.2728
  Epoch [65/100], Batch [94/517], Loss: 0.3763
  Epoch [65/100], Batch [141/517], Loss: 0.3882
  Epoch [65/100], Batch [188/517], Loss: 0.1700
  Epoch [65/100], Batch [235/517], Loss: 0.1875
  Epoch [65/100], Batch [282/517], Loss: 0.2830
  Epoch [65/100], Batch [329/517], Loss: 0.2180
  Epoch [65/100], Batch [376/517], Loss: 0.1782
  Epoch [65/100], Batch [423/517], Loss: 0.2003
  Epoch [65/100], Batch [470/517], Loss: 0.3917
  Epoch [65/100], Batch [517/517], Loss: 0.3900
--- Epoch [65/100] complete. Average Training Loss: 0.2444 ---
--- Time taken for epoch: 314.10 seconds ---
  Epoch [66/100], Batch [47/517], Loss: 0.2768
  Epoch [66/100], Batch [94/517], Loss: 0.1696
  Epoch [66/100], Batch [141/517], Loss: 0.2150
  Epoch [66/100], Batch [188/517], Loss: 0.1257
  Epoch [66/100], Batch [235/517], Loss: 0.1347
  Epoch [66/100], Batch [282/517], Loss: 0.2601
  Epoch [66/100], Batch [329/517], Loss: 0.4187
  Epoch [66/100], Batch [376/517], Loss: 0.4071
  Epoch [66/100], Batch [423/517], Loss: 0.3935
  Epoch [66/100], Batch [470/517], Loss: 0.1761
  Epoch [66/100], Batch [517/517], Loss: 0.2163
--- Epoch [66/100] complete. Average Training Loss: 0.2438 ---
--- Time taken for epoch: 314.03 seconds ---
  Epoch [67/100], Batch [47/517], Loss: 0.2241
  Epoch [67/100], Batch [94/517], Loss: 0.2289
  Epoch [67/100], Batch [141/517], Loss: 0.2649
  Epoch [67/100], Batch [188/517], Loss: 0.1716
  Epoch [67/100], Batch [235/517], Loss: 0.1321
  Epoch [67/100], Batch [282/517], Loss: 0.2033
  Epoch [67/100], Batch [329/517], Loss: 0.3199
  Epoch [67/100], Batch [376/517], Loss: 0.1549
  Epoch [67/100], Batch [423/517], Loss: 0.1658
  Epoch [67/100], Batch [470/517], Loss: 0.2006
  Epoch [67/100], Batch [517/517], Loss: 0.4164
--- Epoch [67/100] complete. Average Training Loss: 0.2454 ---
--- Time taken for epoch: 314.26 seconds ---
  Epoch [68/100], Batch [47/517], Loss: 0.1489
  Epoch [68/100], Batch [94/517], Loss: 0.1715
  Epoch [68/100], Batch [141/517], Loss: 0.1421
  Epoch [68/100], Batch [188/517], Loss: 0.2653
  Epoch [68/100], Batch [235/517], Loss: 0.3952
  Epoch [68/100], Batch [282/517], Loss: 0.2621
  Epoch [68/100], Batch [329/517], Loss: 0.2123
  Epoch [68/100], Batch [376/517], Loss: 0.1321
  Epoch [68/100], Batch [423/517], Loss: 0.2285
  Epoch [68/100], Batch [470/517], Loss: 0.1970
  Epoch [68/100], Batch [517/517], Loss: 0.1400
--- Epoch [68/100] complete. Average Training Loss: 0.2373 ---
--- Time taken for epoch: 314.22 seconds ---
  Epoch [69/100], Batch [47/517], Loss: 0.4087
  Epoch [69/100], Batch [94/517], Loss: 0.2130
  Epoch [69/100], Batch [141/517], Loss: 0.4158
  Epoch [69/100], Batch [188/517], Loss: 0.1721
  Epoch [69/100], Batch [235/517], Loss: 0.1512
  Epoch [69/100], Batch [282/517], Loss: 0.1541
  Epoch [69/100], Batch [329/517], Loss: 0.4318
  Epoch [69/100], Batch [376/517], Loss: 0.1326
  Epoch [69/100], Batch [423/517], Loss: 0.1663
  Epoch [69/100], Batch [470/517], Loss: 0.1891
  Epoch [69/100], Batch [517/517], Loss: 0.1351
--- Epoch [69/100] complete. Average Training Loss: 0.2363 ---
--- Time taken for epoch: 314.23 seconds ---
  Epoch [70/100], Batch [47/517], Loss: 0.1706
  Epoch [70/100], Batch [94/517], Loss: 0.1012
  Epoch [70/100], Batch [141/517], Loss: 0.2281
  Epoch [70/100], Batch [188/517], Loss: 0.4103
  Epoch [70/100], Batch [235/517], Loss: 0.3645
  Epoch [70/100], Batch [282/517], Loss: 0.3819
  Epoch [70/100], Batch [329/517], Loss: 0.2940
  Epoch [70/100], Batch [376/517], Loss: 0.2919
  Epoch [70/100], Batch [423/517], Loss: 0.1515
  Epoch [70/100], Batch [470/517], Loss: 0.1566
  Epoch [70/100], Batch [517/517], Loss: 0.1489
--- Epoch [70/100] complete. Average Training Loss: 0.2417 ---
--- Time taken for epoch: 314.16 seconds ---
  Epoch [71/100], Batch [47/517], Loss: 0.1600
  Epoch [71/100], Batch [94/517], Loss: 0.1899
  Epoch [71/100], Batch [141/517], Loss: 0.1547
  Epoch [71/100], Batch [188/517], Loss: 0.4203
  Epoch [71/100], Batch [235/517], Loss: 0.2502
  Epoch [71/100], Batch [282/517], Loss: 0.1696
  Epoch [71/100], Batch [329/517], Loss: 0.1319
  Epoch [71/100], Batch [376/517], Loss: 0.2301
  Epoch [71/100], Batch [423/517], Loss: 0.1426
  Epoch [71/100], Batch [470/517], Loss: 0.4015
  Epoch [71/100], Batch [517/517], Loss: 0.3998
--- Epoch [71/100] complete. Average Training Loss: 0.2412 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [72/100], Batch [47/517], Loss: 0.1733
  Epoch [72/100], Batch [94/517], Loss: 0.2095
  Epoch [72/100], Batch [141/517], Loss: 0.1710
  Epoch [72/100], Batch [188/517], Loss: 0.4167
  Epoch [72/100], Batch [235/517], Loss: 0.2415
  Epoch [72/100], Batch [282/517], Loss: 0.4049
  Epoch [72/100], Batch [329/517], Loss: 0.1632
  Epoch [72/100], Batch [376/517], Loss: 0.2758
  Epoch [72/100], Batch [423/517], Loss: 0.3363
  Epoch [72/100], Batch [470/517], Loss: 0.1610
  Epoch [72/100], Batch [517/517], Loss: 0.4243
--- Epoch [72/100] complete. Average Training Loss: 0.2389 ---
--- Time taken for epoch: 314.26 seconds ---
  Epoch [73/100], Batch [47/517], Loss: 0.2285
  Epoch [73/100], Batch [94/517], Loss: 0.3232
  Epoch [73/100], Batch [141/517], Loss: 0.2173
  Epoch [73/100], Batch [188/517], Loss: 0.1166
  Epoch [73/100], Batch [235/517], Loss: 0.3944
  Epoch [73/100], Batch [282/517], Loss: 0.2171
  Epoch [73/100], Batch [329/517], Loss: 0.3270
  Epoch [73/100], Batch [376/517], Loss: 0.1792
  Epoch [73/100], Batch [423/517], Loss: 0.1679
  Epoch [73/100], Batch [470/517], Loss: 0.2652
  Epoch [73/100], Batch [517/517], Loss: 0.1906
--- Epoch [73/100] complete. Average Training Loss: 0.2351 ---
--- Time taken for epoch: 314.21 seconds ---
  Epoch [74/100], Batch [47/517], Loss: 0.1840
  Epoch [74/100], Batch [94/517], Loss: 0.2579
  Epoch [74/100], Batch [141/517], Loss: 0.1680
  Epoch [74/100], Batch [188/517], Loss: 0.2985
  Epoch [74/100], Batch [235/517], Loss: 0.2414
  Epoch [74/100], Batch [282/517], Loss: 0.1255
  Epoch [74/100], Batch [329/517], Loss: 0.1981
  Epoch [74/100], Batch [376/517], Loss: 0.2079
  Epoch [74/100], Batch [423/517], Loss: 0.2052
  Epoch [74/100], Batch [470/517], Loss: 0.3959
  Epoch [74/100], Batch [517/517], Loss: 0.3853
--- Epoch [74/100] complete. Average Training Loss: 0.2324 ---
--- Time taken for epoch: 314.23 seconds ---
  Epoch [75/100], Batch [47/517], Loss: 0.1523
  Epoch [75/100], Batch [94/517], Loss: 0.2855
  Epoch [75/100], Batch [141/517], Loss: 0.3734
  Epoch [75/100], Batch [188/517], Loss: 0.2457
  Epoch [75/100], Batch [235/517], Loss: 0.1426
  Epoch [75/100], Batch [282/517], Loss: 0.1428
  Epoch [75/100], Batch [329/517], Loss: 0.1919
  Epoch [75/100], Batch [376/517], Loss: 0.1744
  Epoch [75/100], Batch [423/517], Loss: 0.4246
  Epoch [75/100], Batch [470/517], Loss: 0.1652
  Epoch [75/100], Batch [517/517], Loss: 0.1585
--- Epoch [75/100] complete. Average Training Loss: 0.2328 ---
--- Time taken for epoch: 314.32 seconds ---
 -- Updated Checkpoint: Saved model at 75 epochs.
  Epoch [76/100], Batch [47/517], Loss: 0.4124
  Epoch [76/100], Batch [94/517], Loss: 0.1552
  Epoch [76/100], Batch [141/517], Loss: 0.2269
  Epoch [76/100], Batch [188/517], Loss: 0.4386
  Epoch [76/100], Batch [235/517], Loss: 0.1982
  Epoch [76/100], Batch [282/517], Loss: 0.2760
  Epoch [76/100], Batch [329/517], Loss: 0.1696
  Epoch [76/100], Batch [376/517], Loss: 0.1744
  Epoch [76/100], Batch [423/517], Loss: 0.1343
  Epoch [76/100], Batch [470/517], Loss: 0.3850
  Epoch [76/100], Batch [517/517], Loss: 0.1251
--- Epoch [76/100] complete. Average Training Loss: 0.2440 ---
--- Time taken for epoch: 314.12 seconds ---
  Epoch [77/100], Batch [47/517], Loss: 0.1618
  Epoch [77/100], Batch [94/517], Loss: 0.2459
  Epoch [77/100], Batch [141/517], Loss: 0.2758
  Epoch [77/100], Batch [188/517], Loss: 0.2333
  Epoch [77/100], Batch [235/517], Loss: 0.1606
  Epoch [77/100], Batch [282/517], Loss: 0.1659
  Epoch [77/100], Batch [329/517], Loss: 0.4524
  Epoch [77/100], Batch [376/517], Loss: 0.1390
  Epoch [77/100], Batch [423/517], Loss: 0.1857
  Epoch [77/100], Batch [470/517], Loss: 0.2210
  Epoch [77/100], Batch [517/517], Loss: 0.2070
--- Epoch [77/100] complete. Average Training Loss: 0.2435 ---
--- Time taken for epoch: 314.10 seconds ---
  Epoch [78/100], Batch [47/517], Loss: 0.3999
  Epoch [78/100], Batch [94/517], Loss: 0.1566
  Epoch [78/100], Batch [141/517], Loss: 0.1702
  Epoch [78/100], Batch [188/517], Loss: 0.1254
  Epoch [78/100], Batch [235/517], Loss: 0.4148
  Epoch [78/100], Batch [282/517], Loss: 0.3577
  Epoch [78/100], Batch [329/517], Loss: 0.1412
  Epoch [78/100], Batch [376/517], Loss: 0.3964
  Epoch [78/100], Batch [423/517], Loss: 0.3904
  Epoch [78/100], Batch [470/517], Loss: 0.2186
  Epoch [78/100], Batch [517/517], Loss: 0.1880
--- Epoch [78/100] complete. Average Training Loss: 0.2395 ---
--- Time taken for epoch: 314.26 seconds ---
  Epoch [79/100], Batch [47/517], Loss: 0.1373
  Epoch [79/100], Batch [94/517], Loss: 0.1215
  Epoch [79/100], Batch [141/517], Loss: 0.3923
  Epoch [79/100], Batch [188/517], Loss: 0.1918
  Epoch [79/100], Batch [235/517], Loss: 0.1520
  Epoch [79/100], Batch [282/517], Loss: 0.1467
  Epoch [79/100], Batch [329/517], Loss: 0.1856
  Epoch [79/100], Batch [376/517], Loss: 0.1313
  Epoch [79/100], Batch [423/517], Loss: 0.1470
  Epoch [79/100], Batch [470/517], Loss: 0.2306
  Epoch [79/100], Batch [517/517], Loss: 0.2800
--- Epoch [79/100] complete. Average Training Loss: 0.2355 ---
--- Time taken for epoch: 314.27 seconds ---
  Epoch [80/100], Batch [47/517], Loss: 0.3887
  Epoch [80/100], Batch [94/517], Loss: 0.4216
  Epoch [80/100], Batch [141/517], Loss: 0.1963
  Epoch [80/100], Batch [188/517], Loss: 0.2814
  Epoch [80/100], Batch [235/517], Loss: 0.1594
  Epoch [80/100], Batch [282/517], Loss: 0.1161
  Epoch [80/100], Batch [329/517], Loss: 0.1562
  Epoch [80/100], Batch [376/517], Loss: 0.1336
  Epoch [80/100], Batch [423/517], Loss: 0.1929
  Epoch [80/100], Batch [470/517], Loss: 0.2003
  Epoch [80/100], Batch [517/517], Loss: 0.3842
--- Epoch [80/100] complete. Average Training Loss: 0.2308 ---
--- Time taken for epoch: 314.29 seconds ---
  Epoch [81/100], Batch [47/517], Loss: 0.2569
  Epoch [81/100], Batch [94/517], Loss: 0.1281
  Epoch [81/100], Batch [141/517], Loss: 0.2095
  Epoch [81/100], Batch [188/517], Loss: 0.2049
  Epoch [81/100], Batch [235/517], Loss: 0.0823
  Epoch [81/100], Batch [282/517], Loss: 0.0888
  Epoch [81/100], Batch [329/517], Loss: 0.1832
  Epoch [81/100], Batch [376/517], Loss: 0.1540
  Epoch [81/100], Batch [423/517], Loss: 0.4026
  Epoch [81/100], Batch [470/517], Loss: 0.2168
  Epoch [81/100], Batch [517/517], Loss: 0.1377
--- Epoch [81/100] complete. Average Training Loss: 0.2301 ---
--- Time taken for epoch: 314.22 seconds ---
  Epoch [82/100], Batch [47/517], Loss: 0.3526
  Epoch [82/100], Batch [94/517], Loss: 0.2067
  Epoch [82/100], Batch [141/517], Loss: 0.1706
  Epoch [82/100], Batch [188/517], Loss: 0.2300
  Epoch [82/100], Batch [235/517], Loss: 0.1502
  Epoch [82/100], Batch [282/517], Loss: 0.1634
  Epoch [82/100], Batch [329/517], Loss: 0.1730
  Epoch [82/100], Batch [376/517], Loss: 0.2238
  Epoch [82/100], Batch [423/517], Loss: 0.1725
  Epoch [82/100], Batch [470/517], Loss: 0.4087
  Epoch [82/100], Batch [517/517], Loss: 0.2676
--- Epoch [82/100] complete. Average Training Loss: 0.2302 ---
--- Time taken for epoch: 314.23 seconds ---
  Epoch [83/100], Batch [47/517], Loss: 0.1511
  Epoch [83/100], Batch [94/517], Loss: 0.1092
  Epoch [83/100], Batch [141/517], Loss: 0.1529
  Epoch [83/100], Batch [188/517], Loss: 0.4178
  Epoch [83/100], Batch [235/517], Loss: 0.2148
  Epoch [83/100], Batch [282/517], Loss: 0.1966
  Epoch [83/100], Batch [329/517], Loss: 0.1200
  Epoch [83/100], Batch [376/517], Loss: 0.2043
  Epoch [83/100], Batch [423/517], Loss: 0.1736
  Epoch [83/100], Batch [470/517], Loss: 0.2102
  Epoch [83/100], Batch [517/517], Loss: 0.2620
--- Epoch [83/100] complete. Average Training Loss: 0.2444 ---
--- Time taken for epoch: 314.11 seconds ---
  Epoch [84/100], Batch [47/517], Loss: 0.1488
  Epoch [84/100], Batch [94/517], Loss: 0.1759
  Epoch [84/100], Batch [141/517], Loss: 0.2296
  Epoch [84/100], Batch [188/517], Loss: 0.1224
  Epoch [84/100], Batch [235/517], Loss: 0.3791
  Epoch [84/100], Batch [282/517], Loss: 0.4261
  Epoch [84/100], Batch [329/517], Loss: 0.2505
  Epoch [84/100], Batch [376/517], Loss: 0.2054
  Epoch [84/100], Batch [423/517], Loss: 0.1901
  Epoch [84/100], Batch [470/517], Loss: 0.3776
  Epoch [84/100], Batch [517/517], Loss: 0.2614
--- Epoch [84/100] complete. Average Training Loss: 0.2319 ---
--- Time taken for epoch: 314.08 seconds ---
  Epoch [85/100], Batch [47/517], Loss: 0.2806
  Epoch [85/100], Batch [94/517], Loss: 0.2192
  Epoch [85/100], Batch [141/517], Loss: 0.1391
  Epoch [85/100], Batch [188/517], Loss: 0.1716
  Epoch [85/100], Batch [235/517], Loss: 0.1374
  Epoch [85/100], Batch [282/517], Loss: 0.4372
  Epoch [85/100], Batch [329/517], Loss: 0.2693
  Epoch [85/100], Batch [376/517], Loss: 0.1627
  Epoch [85/100], Batch [423/517], Loss: 0.4151
  Epoch [85/100], Batch [470/517], Loss: 0.4120
  Epoch [85/100], Batch [517/517], Loss: 0.1528
--- Epoch [85/100] complete. Average Training Loss: 0.2392 ---
--- Time taken for epoch: 314.15 seconds ---
  Epoch [86/100], Batch [47/517], Loss: 0.1726
  Epoch [86/100], Batch [94/517], Loss: 0.1883
  Epoch [86/100], Batch [141/517], Loss: 0.4182
  Epoch [86/100], Batch [188/517], Loss: 0.1560
  Epoch [86/100], Batch [235/517], Loss: 0.1275
  Epoch [86/100], Batch [282/517], Loss: 0.3384
  Epoch [86/100], Batch [329/517], Loss: 0.1420
  Epoch [86/100], Batch [376/517], Loss: 0.2959
  Epoch [86/100], Batch [423/517], Loss: 0.1475
  Epoch [86/100], Batch [470/517], Loss: 0.2012
  Epoch [86/100], Batch [517/517], Loss: 0.1593
--- Epoch [86/100] complete. Average Training Loss: 0.2296 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [87/100], Batch [47/517], Loss: 0.2045
  Epoch [87/100], Batch [94/517], Loss: 0.1643
  Epoch [87/100], Batch [141/517], Loss: 0.1873
  Epoch [87/100], Batch [188/517], Loss: 0.1082
  Epoch [87/100], Batch [235/517], Loss: 0.4265
  Epoch [87/100], Batch [282/517], Loss: 0.1623
  Epoch [87/100], Batch [329/517], Loss: 0.0829
  Epoch [87/100], Batch [376/517], Loss: 0.3835
  Epoch [87/100], Batch [423/517], Loss: 0.2893
  Epoch [87/100], Batch [470/517], Loss: 0.1469
  Epoch [87/100], Batch [517/517], Loss: 0.4053
--- Epoch [87/100] complete. Average Training Loss: 0.2278 ---
--- Time taken for epoch: 314.14 seconds ---
  Epoch [88/100], Batch [47/517], Loss: 0.1329
  Epoch [88/100], Batch [94/517], Loss: 0.4058
  Epoch [88/100], Batch [141/517], Loss: 0.1071
  Epoch [88/100], Batch [188/517], Loss: 0.1224
  Epoch [88/100], Batch [235/517], Loss: 0.1225
  Epoch [88/100], Batch [282/517], Loss: 0.2391
  Epoch [88/100], Batch [329/517], Loss: 0.1592
  Epoch [88/100], Batch [376/517], Loss: 0.4078
  Epoch [88/100], Batch [423/517], Loss: 0.3094
  Epoch [88/100], Batch [470/517], Loss: 0.1921
  Epoch [88/100], Batch [517/517], Loss: 0.2271
--- Epoch [88/100] complete. Average Training Loss: 0.2313 ---
--- Time taken for epoch: 314.25 seconds ---
  Epoch [89/100], Batch [47/517], Loss: 0.1677
  Epoch [89/100], Batch [94/517], Loss: 0.2381
  Epoch [89/100], Batch [141/517], Loss: 0.2332
  Epoch [89/100], Batch [188/517], Loss: 0.1216
  Epoch [89/100], Batch [235/517], Loss: 0.2865
  Epoch [89/100], Batch [282/517], Loss: 0.2297
  Epoch [89/100], Batch [329/517], Loss: 0.2556
  Epoch [89/100], Batch [376/517], Loss: 0.1809
  Epoch [89/100], Batch [423/517], Loss: 0.1532
  Epoch [89/100], Batch [470/517], Loss: 0.1915
  Epoch [89/100], Batch [517/517], Loss: 0.4057
--- Epoch [89/100] complete. Average Training Loss: 0.2276 ---
--- Time taken for epoch: 314.12 seconds ---
  Epoch [90/100], Batch [47/517], Loss: 0.3950
  Epoch [90/100], Batch [94/517], Loss: 0.2854
  Epoch [90/100], Batch [141/517], Loss: 0.2958
  Epoch [90/100], Batch [188/517], Loss: 0.1921
  Epoch [90/100], Batch [235/517], Loss: 0.1821
  Epoch [90/100], Batch [282/517], Loss: 0.2009
  Epoch [90/100], Batch [329/517], Loss: 0.1201
  Epoch [90/100], Batch [376/517], Loss: 0.1155
  Epoch [90/100], Batch [423/517], Loss: 0.3828
  Epoch [90/100], Batch [470/517], Loss: 0.3518
  Epoch [90/100], Batch [517/517], Loss: 0.1295
--- Epoch [90/100] complete. Average Training Loss: 0.2375 ---
--- Time taken for epoch: 314.16 seconds ---
  Epoch [91/100], Batch [47/517], Loss: 0.1614
  Epoch [91/100], Batch [94/517], Loss: 0.3843
  Epoch [91/100], Batch [141/517], Loss: 0.1629
  Epoch [91/100], Batch [188/517], Loss: 0.1404
  Epoch [91/100], Batch [235/517], Loss: 0.1297
  Epoch [91/100], Batch [282/517], Loss: 0.3947
  Epoch [91/100], Batch [329/517], Loss: 0.1785
  Epoch [91/100], Batch [376/517], Loss: 0.2686
  Epoch [91/100], Batch [423/517], Loss: 0.1958
  Epoch [91/100], Batch [470/517], Loss: 0.2202
  Epoch [91/100], Batch [517/517], Loss: 0.2986
--- Epoch [91/100] complete. Average Training Loss: 0.2273 ---
--- Time taken for epoch: 314.00 seconds ---
  Epoch [92/100], Batch [47/517], Loss: 0.2542
  Epoch [92/100], Batch [94/517], Loss: 0.1564
  Epoch [92/100], Batch [141/517], Loss: 0.1622
  Epoch [92/100], Batch [188/517], Loss: 0.3007
  Epoch [92/100], Batch [235/517], Loss: 0.1312
  Epoch [92/100], Batch [282/517], Loss: 0.3100
  Epoch [92/100], Batch [329/517], Loss: 0.1636
  Epoch [92/100], Batch [376/517], Loss: 0.1624
  Epoch [92/100], Batch [423/517], Loss: 0.2862
  Epoch [92/100], Batch [470/517], Loss: 0.1984
  Epoch [92/100], Batch [517/517], Loss: 0.1137
--- Epoch [92/100] complete. Average Training Loss: 0.2234 ---
--- Time taken for epoch: 314.19 seconds ---
  Epoch [93/100], Batch [47/517], Loss: 0.2553
  Epoch [93/100], Batch [94/517], Loss: 0.1469
  Epoch [93/100], Batch [141/517], Loss: 0.1488
  Epoch [93/100], Batch [188/517], Loss: 0.1601
  Epoch [93/100], Batch [235/517], Loss: 0.4003
  Epoch [93/100], Batch [282/517], Loss: 0.2129
  Epoch [93/100], Batch [329/517], Loss: 0.2472
  Epoch [93/100], Batch [376/517], Loss: 0.4333
  Epoch [93/100], Batch [423/517], Loss: 0.1697
  Epoch [93/100], Batch [470/517], Loss: 0.2289
  Epoch [93/100], Batch [517/517], Loss: 0.2617
--- Epoch [93/100] complete. Average Training Loss: 0.2419 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [94/100], Batch [47/517], Loss: 0.1354
  Epoch [94/100], Batch [94/517], Loss: 0.1636
  Epoch [94/100], Batch [141/517], Loss: 0.1741
  Epoch [94/100], Batch [188/517], Loss: 0.2997
  Epoch [94/100], Batch [235/517], Loss: 0.1654
  Epoch [94/100], Batch [282/517], Loss: 0.1562
  Epoch [94/100], Batch [329/517], Loss: 0.2969
  Epoch [94/100], Batch [376/517], Loss: 0.3916
  Epoch [94/100], Batch [423/517], Loss: 0.1831
  Epoch [94/100], Batch [470/517], Loss: 0.1623
  Epoch [94/100], Batch [517/517], Loss: 0.2150
--- Epoch [94/100] complete. Average Training Loss: 0.2275 ---
--- Time taken for epoch: 314.13 seconds ---
  Epoch [95/100], Batch [47/517], Loss: 0.3911
  Epoch [95/100], Batch [94/517], Loss: 0.1657
  Epoch [95/100], Batch [141/517], Loss: 0.1496
  Epoch [95/100], Batch [188/517], Loss: 0.1699
  Epoch [95/100], Batch [235/517], Loss: 0.1249
  Epoch [95/100], Batch [282/517], Loss: 0.1014
  Epoch [95/100], Batch [329/517], Loss: 0.1805
  Epoch [95/100], Batch [376/517], Loss: 0.3871
  Epoch [95/100], Batch [423/517], Loss: 0.1200
  Epoch [95/100], Batch [470/517], Loss: 0.1947
  Epoch [95/100], Batch [517/517], Loss: 0.2174
--- Epoch [95/100] complete. Average Training Loss: 0.2272 ---
--- Time taken for epoch: 314.20 seconds ---
  Epoch [96/100], Batch [47/517], Loss: 0.3928
  Epoch [96/100], Batch [94/517], Loss: 0.1505
  Epoch [96/100], Batch [141/517], Loss: 0.2971
  Epoch [96/100], Batch [188/517], Loss: 0.2870
  Epoch [96/100], Batch [235/517], Loss: 0.2044
  Epoch [96/100], Batch [282/517], Loss: 0.1457
  Epoch [96/100], Batch [329/517], Loss: 0.1267
  Epoch [96/100], Batch [376/517], Loss: 0.1847
  Epoch [96/100], Batch [423/517], Loss: 0.1401
  Epoch [96/100], Batch [470/517], Loss: 0.1359
  Epoch [96/100], Batch [517/517], Loss: 0.1730
--- Epoch [96/100] complete. Average Training Loss: 0.2278 ---
--- Time taken for epoch: 314.19 seconds ---
  Epoch [97/100], Batch [47/517], Loss: 0.2603
  Epoch [97/100], Batch [94/517], Loss: 0.1100
  Epoch [97/100], Batch [141/517], Loss: 0.2208
  Epoch [97/100], Batch [188/517], Loss: 0.4170
  Epoch [97/100], Batch [235/517], Loss: 0.3808
  Epoch [97/100], Batch [282/517], Loss: 0.1776
  Epoch [97/100], Batch [329/517], Loss: 0.1340
  Epoch [97/100], Batch [376/517], Loss: 0.4352
  Epoch [97/100], Batch [423/517], Loss: 0.2777
  Epoch [97/100], Batch [470/517], Loss: 0.1657
  Epoch [97/100], Batch [517/517], Loss: 0.1502
--- Epoch [97/100] complete. Average Training Loss: 0.2244 ---
--- Time taken for epoch: 314.26 seconds ---
  Epoch [98/100], Batch [47/517], Loss: 0.1464
  Epoch [98/100], Batch [94/517], Loss: 0.1520
  Epoch [98/100], Batch [141/517], Loss: 0.1720
  Epoch [98/100], Batch [188/517], Loss: 0.1357
  Epoch [98/100], Batch [235/517], Loss: 0.4144
  Epoch [98/100], Batch [282/517], Loss: 0.1223
  Epoch [98/100], Batch [329/517], Loss: 0.3778
  Epoch [98/100], Batch [376/517], Loss: 0.3820
  Epoch [98/100], Batch [423/517], Loss: 0.1419
  Epoch [98/100], Batch [470/517], Loss: 0.4023
  Epoch [98/100], Batch [517/517], Loss: 0.3876
--- Epoch [98/100] complete. Average Training Loss: 0.2277 ---
--- Time taken for epoch: 314.29 seconds ---
  Epoch [99/100], Batch [47/517], Loss: 0.1260
  Epoch [99/100], Batch [94/517], Loss: 0.4018
  Epoch [99/100], Batch [141/517], Loss: 0.1816
  Epoch [99/100], Batch [188/517], Loss: 0.3215
  Epoch [99/100], Batch [235/517], Loss: 0.1581
  Epoch [99/100], Batch [282/517], Loss: 0.3877
  Epoch [99/100], Batch [329/517], Loss: 0.1734
  Epoch [99/100], Batch [376/517], Loss: 0.1870
  Epoch [99/100], Batch [423/517], Loss: 0.2065
  Epoch [99/100], Batch [470/517], Loss: 0.3927
  Epoch [99/100], Batch [517/517], Loss: 0.1575
--- Epoch [99/100] complete. Average Training Loss: 0.2249 ---
--- Time taken for epoch: 314.18 seconds ---
  Epoch [100/100], Batch [47/517], Loss: 0.0973
  Epoch [100/100], Batch [94/517], Loss: 0.1360
  Epoch [100/100], Batch [141/517], Loss: 0.1012
  Epoch [100/100], Batch [188/517], Loss: 0.3898
  Epoch [100/100], Batch [235/517], Loss: 0.2127
  Epoch [100/100], Batch [282/517], Loss: 0.3751
  Epoch [100/100], Batch [329/517], Loss: 0.1743
  Epoch [100/100], Batch [376/517], Loss: 0.1894
  Epoch [100/100], Batch [423/517], Loss: 0.3940
  Epoch [100/100], Batch [470/517], Loss: 0.2021
  Epoch [100/100], Batch [517/517], Loss: 0.3779
--- Epoch [100/100] complete. Average Training Loss: 0.2241 ---
--- Time taken for epoch: 314.28 seconds ---
 -- Updated Checkpoint: Saved model at 100 epochs.
UNet training finished.
UNet training process completed.
